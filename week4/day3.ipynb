{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a6ab9a2-28a2-445d-8512-a0dc8d1b54e9",
   "metadata": {},
   "source": [
    "# Code Generator\n",
    "\n",
    "The requirement: use a Frontier model to generate high performance C++ code from Python code\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b7a7688",
   "metadata": {},
   "source": [
    "different LLM leaderboards-\n",
    "1) https://www.vellum.ai/llm-leaderboard?utm_source=yahoo&utm_medium=organic\n",
    "2) huggingface leaderboard\n",
    "3) https://artificialanalysis.ai/leaderboards/models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5ccb926-7b49-44a4-99ab-8ef20b5778c0",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left;\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/resources.jpg\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#f71;\">Reminder: fetch latest code</h2>\n",
    "            <span style=\"color:#f71;\">I'm continually improving these labs, adding more examples and exercises.\n",
    "            At the start of each week, it's worth checking you have the latest code.<br/>\n",
    "            First do a <a href=\"https://chatgpt.com/share/6734e705-3270-8012-a074-421661af6ba9\">git pull and merge your changes as needed</a>. Any problems? Try asking ChatGPT to clarify how to merge - or contact me!<br/><br/>\n",
    "            After you've pulled the code, from the llm_engineering directory, in a Cursor Terminal, run:<br/>\n",
    "            <code>uv sync</code><br/>\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d90e04a2-5b8a-4fd5-9db8-27c02f033313",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left;\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/important.jpg\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h1 style=\"color:#900;\">Important Note</h1>\n",
    "            <span style=\"color:#900;\">\n",
    "            In this lab, I use high end models GPT 5, Claude 4.5 Sonnet, Gemini 2.5 Pro, Grok 4, which are the slightly higher priced models. The costs are still low, but if you'd prefer to keep costs ultra low, please pick lower cost models like gpt-5-nano.\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e610bf56-a46e-4aff-8de1-ab49d62b1ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "import subprocess\n",
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f672e1c-87e9-4865-b760-370fa605e614",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI API Key exists and begins sk-proj-\n",
      "Anthropic API Key not set (and this is optional)\n",
      "Google API Key not set (and this is optional)\n",
      "Grok API Key not set (and this is optional)\n"
     ]
    }
   ],
   "source": [
    "load_dotenv(override=True)\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "anthropic_api_key = os.getenv('ANTHROPIC_API_KEY')\n",
    "google_api_key = os.getenv('GOOGLE_API_KEY')\n",
    "grok_api_key = os.getenv('GROK_API_KEY')\n",
    "\n",
    "if openai_api_key:\n",
    "    print(f\"OpenAI API Key exists and begins {openai_api_key[:8]}\")\n",
    "else:\n",
    "    print(\"OpenAI API Key not set\")\n",
    "    \n",
    "if anthropic_api_key:\n",
    "    print(f\"Anthropic API Key exists and begins {anthropic_api_key[:7]}\")\n",
    "else:\n",
    "    print(\"Anthropic API Key not set (and this is optional)\")\n",
    "\n",
    "if google_api_key:\n",
    "    print(f\"Google API Key exists and begins {google_api_key[:2]}\")\n",
    "else:\n",
    "    print(\"Google API Key not set (and this is optional)\")\n",
    "\n",
    "if grok_api_key:\n",
    "    print(f\"Grok API Key exists and begins {grok_api_key[:4]}\")\n",
    "else:\n",
    "    print(\"Grok API Key not set (and this is optional)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "59863df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to client libraries\n",
    "\n",
    "openai = OpenAI()\n",
    "\n",
    "anthropic_url = \"https://api.anthropic.com/v1/\"\n",
    "gemini_url = \"https://generativelanguage.googleapis.com/v1beta/openai/\"\n",
    "grok_url = \"https://api.x.ai/v1\"\n",
    "\n",
    "anthropic = OpenAI(api_key=anthropic_api_key, base_url=anthropic_url)\n",
    "gemini = OpenAI(api_key=google_api_key, base_url=gemini_url)\n",
    "grok = OpenAI(api_key=grok_api_key, base_url=grok_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8aa149ed-9298-4d69-8fe2-8f5de0f667da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPENAI_MODEL = \"gpt-5\"\n",
    "CLAUDE_MODEL = \"claude-sonnet-4-5-20250929\"\n",
    "GROK_MODEL = \"grok-4\"\n",
    "GEMINI_MODEL = \"gemini-2.5-pro\"\n",
    "\n",
    "# Want to keep costs ultra-low? Uncomment these lines:\n",
    "\n",
    "OPENAI_MODEL = \"gpt-5-nano\"\n",
    "# CLAUDE_MODEL = \"claude-3-5-haiku-latest\"\n",
    "# GROK_MODEL = \"grok-4-fast-non-reasoning\"\n",
    "# GEMINI_MODEL = \"gemini-2.5-flash-lite\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eab38a7",
   "metadata": {},
   "source": [
    "## PLEASE NOTE:\n",
    "\n",
    "We will be writing a solution to convert Python into efficient, optimized C++ code for your machine, which can be compiled to native machine code and executed.\n",
    "\n",
    "It is not necessary for you to execute the code yourself - that's not the point of the exercise!\n",
    "\n",
    "But if you would like to (because it's satisfying!) then I'm including the steps here. Very optional!\n",
    "\n",
    "As an alternative, I'll also show you a website where you can run the C++ code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a2fbb68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'os': {'system': 'Darwin',\n",
       "  'arch': 'arm64',\n",
       "  'release': '24.6.0',\n",
       "  'version': 'Darwin Kernel Version 24.6.0: Mon Jul 14 11:30:51 PDT 2025; root:xnu-11417.140.69~1/RELEASE_ARM64_T8112',\n",
       "  'kernel': '24.6.0',\n",
       "  'distro': None,\n",
       "  'wsl': False,\n",
       "  'rosetta2_translated': False,\n",
       "  'target_triple': 'arm64-apple-darwin24.6.0'},\n",
       " 'package_managers': ['xcode-select (CLT)'],\n",
       " 'cpu': {'brand': 'Apple M2',\n",
       "  'cores_logical': 8,\n",
       "  'cores_physical': 8,\n",
       "  'simd': []},\n",
       " 'toolchain': {'compilers': {'gcc': 'Apple clang version 17.0.0 (clang-1700.0.13.3)',\n",
       "   'g++': 'Apple clang version 17.0.0 (clang-1700.0.13.3)',\n",
       "   'clang': 'Apple clang version 17.0.0 (clang-1700.0.13.3)',\n",
       "   'msvc_cl': ''},\n",
       "  'build_tools': {'cmake': '', 'ninja': '', 'make': 'GNU Make 3.81'},\n",
       "  'linkers': {'ld_lld': ''}}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from system_info import retrieve_system_info\n",
    "\n",
    "system_info = retrieve_system_info()\n",
    "system_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c6d29a5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Short answer:\n",
       "- You already have a C++ compiler on your Mac (Apple clang via Xcode Command Line Tools). The system info shows clang/gcc wrappers provided by Apple clang, and xcode-select (CLT) is listed.\n",
       "- To compile and run main.cpp the simplest way is:\n",
       "  - In terminal: clang++ main.cpp -o main; ./main\n",
       "\n",
       "If you don’t have the Command Line Tools installed yet, I’ve included how to install them below.\n",
       "\n",
       "Detailed guidance\n",
       "\n",
       "1) Do you need to install a compiler?\n",
       "- Based on your system info, no. You have Apple clang (clang) available via Xcode Command Line Tools.\n",
       "- If you ever don’t have CLT installed, install with:\n",
       "  - Open Terminal and run: xcode-select --install\n",
       "  - Follow the prompts to complete the installation\n",
       "  - Verify: clang++ --version\n",
       "\n",
       "2) The simplest way to compile and run (manual steps)\n",
       "- Open Terminal\n",
       "- Compile: clang++ main.cpp -o main\n",
       "- Run: ./main\n",
       "\n",
       "3) If you want to automate this from Python (fastest runtime option)\n",
       "- Objective: compile with optimization for speed, then run the executable\n",
       "- Use these exact command lists:\n",
       "\n",
       "compile_command = [\"clang++\", \"-O3\", \"main.cpp\", \"-o\", \"main\"]\n",
       "run_command = [\"./main\"]\n",
       "\n",
       "Notes:\n",
       "- -O3 enables aggressive optimizations for speed.\n",
       "- If you prefer to keep things simpler or don’t care about the tiniest edge in performance, you can drop -O3 and use just [\"clang++\", \"main.cpp\", \"-o\", \"main\"].\n",
       "- If you want to experiment with even more aggressive optimization, you could try -Ofast (with caution), or add -flto for link-time optimization, but for a single-file compile these are usually not necessary.\n",
       "\n",
       "4) Optional alternative (using g++)\n",
       "- If you specifically want to use the GNU g++ wrapper (also available on macOS), you could use:\n",
       "  - compile_command = [\"g++\", \"-O3\", \"main.cpp\", \"-o\", \"main\"]\n",
       "  - run_command = [\"./main\"]\n",
       "- However, since your system shows Apple clang tooling, clang++ is the typical choice.\n",
       "\n",
       "What to copy-paste exactly (for Python usage)\n",
       "- To compile:\n",
       "  compile_command = [\"clang++\", \"-O3\", \"main.cpp\", \"-o\", \"main\"]\n",
       "- To run:\n",
       "  run_command = [\"./main\"]\n",
       "\n",
       "If you want, tell me your exact main.cpp (or any build flags you need), and I can tailor the commands (and Python snippet) to match your file layout or any additional libraries you’re using."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "message = f\"\"\"\n",
    "Here is a report of the system information for my computer.\n",
    "I want to run a C++ compiler to compile a single C++ file called main.cpp and then execute it in the simplest way possible.\n",
    "Please reply with whether I need to install any C++ compiler to do this. If so, please provide the simplest step by step instructions to do so.\n",
    "\n",
    "If I'm already set up to compile C++ code, then I'd like to run something like this in Python to compile and execute the code:\n",
    "```python\n",
    "compile_command = # something here - to achieve the fastest possible runtime performance\n",
    "compile_result = subprocess.run(compile_command, check=True, text=True, capture_output=True)\n",
    "run_command = # something here\n",
    "run_result = subprocess.run(run_command, check=True, text=True, capture_output=True)\n",
    "return run_result.stdout\n",
    "```\n",
    "Please tell me exactly what I should use for the compile_command and run_command.\n",
    "\n",
    "System information:\n",
    "{system_info}\n",
    "\"\"\"\n",
    "\n",
    "response = openai.chat.completions.create(model=OPENAI_MODEL, messages=[{\"role\": \"user\", \"content\": message}])\n",
    "display(Markdown(response.choices[0].message.content))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81e92c12",
   "metadata": {},
   "source": [
    "## If you need to install something\n",
    "\n",
    "If you would like to, please follow GPTs instructions! Then rerun the analysis afterwards (you might need to Restart the notebook) to confirm you're set.\n",
    "\n",
    "You should now be equipped with the command to compile the code, and the command to run it!\n",
    "\n",
    "Enter that in the cell below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d734a634",
   "metadata": {},
   "outputs": [],
   "source": [
    "compile_command = [\"clang++\", \"-std=c++17\", \"-Ofast\", \"-mcpu=native\", \"-flto=thin\", \"-fvisibility=hidden\", \"-DNDEBUG\", \"main.cpp\", \"-o\", \"main\"]\n",
    "run_command = [\"./main\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0b0a437",
   "metadata": {},
   "source": [
    "## And now, on with the main task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6896636f-923e-4a2c-9d6c-fac07828a201",
   "metadata": {},
   "outputs": [],
   "source": [
    "# system_prompt = \"\"\"\n",
    "# Your task is to convert Python code into high performance C++ code.\n",
    "# Respond only with C++ code. Do not provide any explanation other than occasional comments.\n",
    "# The C++ response needs to produce an identical output in the fastest possible time.\n",
    "# \"\"\"\n",
    "\n",
    "system_prompt = \"\"\"\n",
    "Your task is to convert Python code into high performance java code.\n",
    "Respond only with java code. Do not provide any explanation other than occasional comments.\n",
    "The java response needs to produce an identical output in the fastest possible time.\n",
    "\"\"\"\n",
    "\n",
    "# def user_prompt_for(python):\n",
    "#     return f\"\"\"\n",
    "# Port this Python code to C++ with the fastest possible implementation that produces identical output in the least time.\n",
    "# The system information is:\n",
    "# {system_info}\n",
    "# Your response will be written to a file called main.cpp and then compiled and executed; the compilation command is:\n",
    "# {compile_command}\n",
    "# Respond only with C++ code.\n",
    "# Python code to port:\n",
    "\n",
    "# ```python\n",
    "# {python}\n",
    "# ```\n",
    "# \"\"\"\n",
    "\n",
    "def user_prompt_for(python):\n",
    "    return f\"\"\"\n",
    "Port this Python code to java with the fastest possible implementation that produces identical output in the least time.\n",
    "The system information is:\n",
    "{system_info}\n",
    "Your response will be written to a file called main.java and then compiled and executed; the compilation command is:\n",
    "{compile_command}\n",
    "Respond only with java code.\n",
    "Python code to port:\n",
    "\n",
    "```python\n",
    "{python}\n",
    "```\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8e7b3546-57aa-4c29-bc5d-f211970d04eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def messages_for(python):\n",
    "    return [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_prompt_for(python)}\n",
    "    ]\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c6190659-f54c-4951-bef4-4960f8e51cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def write_output(cpp):\n",
    "#     with open(\"main.cpp\", \"w\", encoding=\"utf-8\") as f:\n",
    "#         f.write(cpp)\n",
    "\n",
    "def write_output(cpp):\n",
    "    with open(\"main.java\", \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(cpp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e7d2fea8-74c6-4421-8f1e-0e76d5b201b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def port(client, model, python):\n",
    "    reasoning_effort = \"high\" if 'gpt' in model else None\n",
    "    response = client.chat.completions.create(model=model, messages=messages_for(python), reasoning_effort=reasoning_effort)\n",
    "    reply = response.choices[0].message.content\n",
    "    reply = reply.replace('```cpp','').replace('```','')\n",
    "    write_output(reply)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a1cbb778-fa57-43de-b04b-ed523f396c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "pi = \"\"\"\n",
    "import time\n",
    "\n",
    "def calculate(iterations, param1, param2):\n",
    "    result = 1.0\n",
    "    for i in range(1, iterations+1):\n",
    "        j = i * param1 - param2\n",
    "        result -= (1/j)\n",
    "        j = i * param1 + param2\n",
    "        result += (1/j)\n",
    "    return result\n",
    "\n",
    "start_time = time.time()\n",
    "result = calculate(200_000_000, 4, 1) * 4\n",
    "end_time = time.time()\n",
    "\n",
    "print(f\"Result: {result:.12f}\")\n",
    "print(f\"Execution Time: {(end_time - start_time):.6f} seconds\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7fe1cd4b-d2c5-4303-afed-2115a3fef200",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_python(code):\n",
    "    globals = {\"__builtins__\": __builtins__}\n",
    "    exec(code, globals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7faa90da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: 3.141592656089\n",
      "Execution Time: 14.434667 seconds\n"
     ]
    }
   ],
   "source": [
    "run_python(pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "105db6f9-343c-491d-8e44-3a5328b81719",
   "metadata": {},
   "outputs": [],
   "source": [
    "port(openai, OPENAI_MODEL, pi)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf8f8018-f64d-425c-a0e1-d7862aa9592d",
   "metadata": {},
   "source": [
    "# Compiling C++ and executing\n",
    "\n",
    "This next cell contains the command to compile a C++ file based on the instructions from GPT.\n",
    "\n",
    "Again, it's not crucial to do this step if you don't wish to!\n",
    "\n",
    "OR alternatively: student Sandeep K.G. points out that you can run Python and C++ code online to test it out that way. Thank you Sandeep!  \n",
    "> Not an exact comparison but you can still get the idea of performance difference.  \n",
    "> For example here: https://www.programiz.com/cpp-programming/online-compiler/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4194e40c-04ab-4940-9d64-b4ad37c5bb40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the commands from GPT 5\n",
    "\n",
    "def compile_and_run():\n",
    "    subprocess.run(compile_command, check=True, text=True, capture_output=True)\n",
    "    print(subprocess.run(run_command, check=True, text=True, capture_output=True).stdout)\n",
    "    print(subprocess.run(run_command, check=True, text=True, capture_output=True).stdout)\n",
    "    print(subprocess.run(run_command, check=True, text=True, capture_output=True).stdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "22f8f43a",
   "metadata": {},
   "outputs": [
    {
     "ename": "CalledProcessError",
     "evalue": "Command '['clang++', '-std=c++17', '-Ofast', '-mcpu=native', '-flto=thin', '-fvisibility=hidden', '-DNDEBUG', 'main.cpp', '-o', 'main']' returned non-zero exit status 1.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mCalledProcessError\u001b[39m                        Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[28]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mcompile_and_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 4\u001b[39m, in \u001b[36mcompile_and_run\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcompile_and_run\u001b[39m():\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m     \u001b[43msubprocess\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcompile_command\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcapture_output\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m      5\u001b[39m     \u001b[38;5;28mprint\u001b[39m(subprocess.run(run_command, check=\u001b[38;5;28;01mTrue\u001b[39;00m, text=\u001b[38;5;28;01mTrue\u001b[39;00m, capture_output=\u001b[38;5;28;01mTrue\u001b[39;00m).stdout)\n\u001b[32m      6\u001b[39m     \u001b[38;5;28mprint\u001b[39m(subprocess.run(run_command, check=\u001b[38;5;28;01mTrue\u001b[39;00m, text=\u001b[38;5;28;01mTrue\u001b[39;00m, capture_output=\u001b[38;5;28;01mTrue\u001b[39;00m).stdout)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.12.11-macos-aarch64-none/lib/python3.12/subprocess.py:571\u001b[39m, in \u001b[36mrun\u001b[39m\u001b[34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[39m\n\u001b[32m    569\u001b[39m     retcode = process.poll()\n\u001b[32m    570\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m check \u001b[38;5;129;01mand\u001b[39;00m retcode:\n\u001b[32m--> \u001b[39m\u001b[32m571\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m CalledProcessError(retcode, process.args,\n\u001b[32m    572\u001b[39m                                  output=stdout, stderr=stderr)\n\u001b[32m    573\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m CompletedProcess(process.args, retcode, stdout, stderr)\n",
      "\u001b[31mCalledProcessError\u001b[39m: Command '['clang++', '-std=c++17', '-Ofast', '-mcpu=native', '-flto=thin', '-fvisibility=hidden', '-DNDEBUG', 'main.cpp', '-o', 'main']' returned non-zero exit status 1."
     ]
    }
   ],
   "source": [
    "compile_and_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faaa39de",
   "metadata": {},
   "outputs": [],
   "source": [
    "19.178207/0.082168"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f3b8ef9",
   "metadata": {},
   "source": [
    "## OK let's try the other contenders!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "983a11fe-e24d-4c65-8269-9802c5ef3ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "port(anthropic, CLAUDE_MODEL, pi)\n",
    "compile_and_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "138f63c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "port(grok, GROK_MODEL, pi)\n",
    "compile_and_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a0243c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "port(gemini, GEMINI_MODEL, pi)\n",
    "compile_and_run()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0689e200",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ffb0bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\"\"\n",
    "In Ed's experiments, the performance speedups were:\n",
    "\n",
    "4th place: Claude Sonnet 4.5: {19.178207/0.104241:.0f}X speedup\n",
    "3rd place: GPT-5: {19.178207/0.082168:.0f}X speedup\n",
    "2nd place: Grok 4: {19.178207/0.018092:.0f}X speedup\n",
    "1st place: Gemini 2.5 Pro: {19.178207/0.013314:.0f}X speedup\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d58753b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7202e513",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
