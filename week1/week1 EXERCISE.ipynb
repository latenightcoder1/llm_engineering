{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe12c203-e6a6-452c-a655-afb8a03a4ff5",
   "metadata": {},
   "source": [
    "# End of week 1 exercise\n",
    "\n",
    "To demonstrate your familiarity with OpenAI API, and also Ollama, build a tool that takes a technical question,  \n",
    "and responds with an explanation. This is a tool that you will be able to use yourself during the course!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c1070317-3ed9-4659-abe3-828943230e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from IPython.display import Markdown, display,update_display\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4a456906-915a-4bfd-bb9d-57e505c5093f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants\n",
    "\n",
    "MODEL_GPT = 'gpt-4o-mini'\n",
    "MODEL_LLAMA = 'llama3.2:1b'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a8d7923c-5f28-4c30-8556-342d7c8497c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up environment\n",
    "load_dotenv(override=True)\n",
    "api_key = os.getenv('OPENAI_API_KEY')\n",
    "openai = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f0d0137-52b0-47a8-81a8-11a90a010798",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here is the question; type over this to ask something new\n",
    "\n",
    "question = \"\"\"\n",
    "Please explain what this code does and why:\n",
    "yield from {book.get(\"author\") for book in books if book.get(\"author\")}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "415f4f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"\n",
    "You are a helpful assistant and expert in python and code who can explain code.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "60ce7000-a4a5-4cce-a261-e75ef45063b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "This line of Python code is using `yield from` to yield values from a generator expression that processes a collection called `books`. Let's break it down step by step:\n",
       "\n",
       "### Components of the Code\n",
       "\n",
       "1. **Set comprehension**: \n",
       "   ```python\n",
       "   {book.get(\"author\") for book in books if book.get(\"author\")}\n",
       "   ```\n",
       "   - This creates a set of authors from the `books` collection.\n",
       "   - For each `book` in `books`, it attempts to get the value associated with the key `\"author\"` using `book.get(\"author\")`.\n",
       "   - The expression `if book.get(\"author\")` filters out any books where the author is not present (i.e., returns `None` or any falsey value).\n",
       "   - The result is a set of unique authors that exist in the `books` collection.\n",
       "\n",
       "2. **`yield from`**:\n",
       "   ```python\n",
       "   yield from ...\n",
       "   ```\n",
       "   - This statement is used within a generator function. It takes an iterable and yields each of its items one at a time.\n",
       "   - In this case, it will yield each author obtained from the set comprehension above. \n",
       "\n",
       "### Full Explanation\n",
       "\n",
       "- When this line is executed in the context of a generator function, it will iterate over the set produced by the comprehension and yield each author one by one.\n",
       "- The use of a set ensures that any duplicate authors across different books are filtered out, so each author will only be yielded once.\n",
       "\n",
       "### Why Use This Code?\n",
       "\n",
       "1. **Efficiency**: Using a set comprehension is an efficient way to collect unique values (authors) while filtering out any that are missing or not provided.\n",
       "  \n",
       "2. **Generators**: The use of `yield from` makes it simple to yield results one-by-one, which is memory-efficient, particularly if the set of authors is large.\n",
       "\n",
       "3. **Readability**: This construction combines the set comprehension and generator yielding in a clear and concise manner, enhancing readability of the code.\n",
       "\n",
       "### Example\n",
       "\n",
       "Suppose you have a list of dictionaries representing books:\n",
       "\n",
       "```python\n",
       "books = [\n",
       "    {\"title\": \"Book A\", \"author\": \"Author 1\"},\n",
       "    {\"title\": \"Book B\", \"author\": \"Author 2\"},\n",
       "    {\"title\": \"Book C\", \"author\": \"Author 1\"},  # Duplicate\n",
       "    {\"title\": \"Book D\"},  # No author\n",
       "    {\"title\": \"Book E\", \"author\": None},  # No author\n",
       "]\n",
       "```\n",
       "\n",
       "Executing the line of code would yield:\n",
       "- \"Author 1\"\n",
       "- \"Author 2\"\n",
       "\n",
       "In a generator context, you would call it and receive one author at a time without loading the entire list into memory.\n",
       "\n",
       "### Summary\n",
       "\n",
       "This code succinctly extracts and yields unique authors from a collection of books while handling cases where an author may not be specified, all while maintaining memory efficiency through the use of a generator."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get gpt-4o-mini to answer, with streaming\n",
    "stream=openai.chat.completions.create(model=MODEL_GPT, messages=[\n",
    "    {\"role\": \"system\", \"content\": system_prompt},\n",
    "    {\"role\": \"user\", \"content\": question}\n",
    "    ],\n",
    "    stream=True)\n",
    "response = \"\"\n",
    "display_handle = display(Markdown(\"\"), display_id=True)\n",
    "for chunk in stream:\n",
    "    response += chunk.choices[0].delta.content or ''\n",
    "    update_display(Markdown(response), display_id=display_handle.display_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8f7c8ea8-4082-4ad0-8751-3301adcf6538",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This line of code is using the built-in `for` loop in Python along with a generator expression, `yield from`, and list comprehension to extract specific authors from a collection of books. Here's a breakdown of what it does and why:\n",
      "\n",
      "- `books`: This will be replaced by a real variable for demonstration purposes.\n",
      "  \n",
      "  - `book.get(\"author\")`: Retrieves the author of each book.\n",
      "\n",
      "- `if book.get(\"author\")`: This condition filters out any books that are missing their authors. If you have more than one book with different authors or no authors at all, this line won't execute because it's filtering out ones where there aren't any relevant data.\n",
      "  \n",
      "- `{book.get(\"author\") for book in books if book.get(\"author\")}` transforms the results of `if`. It returns a generator that yields each author retrieved.\n",
      "\n",
      "- `yield from` is a function decorator. When used, it turns the list comprehension above into a generator expression which lazily iterates over the authors found within a list of dictionaries (`books`). If the value is not available, none will be printed.\n",
      "\n",
      "\n",
      "Here's an example to demonstrate how all this works:\n",
      "\n",
      "Let's say you have the following dictionary `books` and the following list of book data.\n",
      "\n",
      "```python\n",
      "# sample data structures\n",
      "books = [\n",
      "    {\"title\": \"Book1\", \"author\": \"AuthorA\", \"country\": \"USA\"},\n",
      "    {\"title\": \"Book2\", \"_id\": 1},\n",
      "    {\"title\": \"Book3\", \"author\": \"AuthorB\"},  # This has no valid author\n",
      "]\n",
      "\n",
      "for book in books:\n",
      "    print(book[\"author\"])  # 'AuthorB'\n",
      "```\n",
      "\n",
      "Now let's apply the given code snippet:\n",
      "\n",
      "```python\n",
      "# applying the code snippet\n",
      "\n",
      "result = yield from (\n",
      "    book.get(\"author\") \n",
      "    for book in books         \n",
      "    if book.get(\"author\")\n",
      ")\n",
      "print(list(result))  # ['AuthorA', None]\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "# Get Llama 3.2 to answer\n",
    "OLLAMA_BASE_URL = \"http://localhost:11434/v1\"\n",
    "ollama = OpenAI(base_url=OLLAMA_BASE_URL, api_key='ollama')\n",
    "llamaStream = ollama.chat.completions.create(model=MODEL_LLAMA, messages=[\n",
    "    {\"role\": \"system\", \"content\": system_prompt},\n",
    "    {\"role\": \"user\", \"content\": question}\n",
    "])\n",
    "print(llamaStream.choices[0].message.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
